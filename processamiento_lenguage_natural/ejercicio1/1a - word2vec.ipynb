{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"data":{"text/plain":["{'de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que'}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["#Aquí se supone que no habrá puntuación para manejar\n","\n","vocab = set()\n","\n","for text in corpus:\n","    words = text.lower().split(' ')\n","    vocab.update(words)\n","\n","vocab\n"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["['de', 'dia', 'martes', 'el', 'que', 'muchas', 'es', 'gracias', 'hoy']\n"]},{"data":{"text/plain":["[[0, 1, 0, 0, 1, 0, 1, 0, 1],\n"," [1, 1, 1, 1, 0, 0, 1, 0, 1],\n"," [0, 0, 1, 0, 0, 1, 0, 1, 0]]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["one_hot_encoding= []\n","\n","vocab_list = list(vocab)\n","print(vocab_list)\n","\n","for text in corpus:\n","    encoding = []\n","    words = text.lower().split(' ')\n","\n","    for i, word in enumerate(vocab_list):\n","        encoding.append(int(word in words))\n","\n","    one_hot_encoding.append(encoding)\n","\n","one_hot_encoding\n","\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["['de', 'dia', 'martes', 'el', 'que', 'muchas', 'es', 'gracias', 'hoy']\n"]},{"data":{"text/plain":["[[0, 1, 0, 0, 1, 0, 1, 0, 1],\n"," [1, 1, 2, 1, 0, 0, 1, 0, 1],\n"," [0, 0, 1, 0, 0, 1, 0, 1, 0]]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["frequency_vector = []\n","\n","vocab_list = list(vocab)\n","print(vocab_list)\n","\n","for text in corpus:\n","    vector = [0]*len(vocab_list)\n","    words = text.lower().split(' ')\n","\n","    for word in words:\n","        if word in vocab_list:\n","            vector[vocab_list.index(word)] += 1\n","\n","    frequency_vector.append(vector)\n","\n","frequency_vector\n","\n","    "]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["['de', 'dia', 'martes', 'el', 'que', 'muchas', 'es', 'gracias', 'hoy']\n","[1.0986122886681096, 0.4054651081081644, 0.4054651081081644, 1.0986122886681096, 1.0986122886681096, 1.0986122886681096, 0.4054651081081644, 1.0986122886681096, 0.4054651081081644]\n"]},{"data":{"text/plain":["[[0.0,\n","  0.4054651081081644,\n","  0.0,\n","  0.0,\n","  1.0986122886681096,\n","  0.0,\n","  0.4054651081081644,\n","  0.0,\n","  0.4054651081081644],\n"," [1.0986122886681096,\n","  0.4054651081081644,\n","  0.8109302162163288,\n","  1.0986122886681096,\n","  0.0,\n","  0.0,\n","  0.4054651081081644,\n","  0.0,\n","  0.4054651081081644],\n"," [0.0,\n","  0.0,\n","  0.4054651081081644,\n","  0.0,\n","  0.0,\n","  1.0986122886681096,\n","  0.0,\n","  1.0986122886681096,\n","  0.0]]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["tf_idf = []\n","\n","vocab_list = list(vocab)\n","print(vocab_list)\n","\n","#Calculate IDF\n","idf_vector = [0]*len(vocab_list)\n","for text in corpus:\n","    words = text.lower().split(' ')\n","\n","    for word in vocab_list:\n","        if word in words:\n","            idf_vector[vocab_list.index(word)] += 1\n","\n","for i in range(len(idf_vector)):\n","    idf_vector[i] = np.log(len(corpus) / idf_vector[i])\n","\n","print(idf_vector)\n","\n","\n","for text in corpus:\n","    tf_vector = [0]*len(vocab_list)\n","    words = text.lower().split(' ')\n","\n","    #Calculate TF term\n","    for word in words:\n","        if word in vocab_list:\n","            tf_vector[vocab_list.index(word)] += 1\n","\n","    #Calculate TF-IDF\n","    for i in range(len(tf_vector)):\n","        tf_vector[i] = tf_vector[i]*idf_vector[i]\n","\n","    tf_idf.append(tf_vector)\n","\n","tf_idf\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"data":{"text/plain":["['martes muchas gracias', 'que dia es hoy', 'martes el dia de hoy es martes']"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["def sort_by_tf_idf_similarity(corpus, index):\n","\n","    tf_idf = []\n","\n","    vocab_list = list(vocab)\n","\n","    #Calculate IDF\n","    idf_vector = [0]*len(vocab_list)\n","    for text in corpus:\n","        words = text.lower().split(' ')\n","\n","        for word in vocab_list:\n","            if word in words:\n","                idf_vector[vocab_list.index(word)] += 1\n","\n","    for i in range(len(idf_vector)):\n","        idf_vector[i] = np.log(len(corpus) / idf_vector[i])\n","\n","    #Calculate TF\n","    for text in corpus:\n","        tf_vector = [0]*len(vocab_list)\n","        words = text.lower().split(' ')\n","\n","        #Calculate TF term\n","        for word in words:\n","            if word in vocab_list:\n","                tf_vector[vocab_list.index(word)] += 1\n","\n","        #Calculate TF-IDF\n","        for i in range(len(tf_vector)):\n","            tf_vector[i] = tf_vector[i]*idf_vector[i]\n","\n","        tf_idf.append(tf_vector)\n","\n","\n","    dtype = [('document', int), ('similarity', float)]\n","    values = []\n","\n","    #Calculate similarity of each document\n","    for i, text in enumerate(tf_idf):\n","        similarity = cosine_similarity(np.asarray(tf_idf[index]), np.asarray(text))\n","        values.append((i, similarity))\n","\n","    #Create a temporary array to sort the documents\n","    tmp_array = np.array(values, dtype=dtype)\n","    tmp_sorted = np.sort(tmp_array, order='similarity')\n","\n","    sorted_corpus = []\n","    for i, _ in tmp_sorted:\n","        sorted_corpus.append(corpus[i])\n","\n","    return sorted_corpus    \n","\n","sort_by_tf_idf_similarity(corpus, 1)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
